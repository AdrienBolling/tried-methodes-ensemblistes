{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagged Decision Trees for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.77 (+/- 0.04)\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\",names=names)\n",
    "\n",
    "array = dataframe.values\n",
    "x = array[:,0:8]\n",
    "y = array[:,8]\n",
    "max_features = 3\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=2020,shuffle=True)\n",
    "rf = DecisionTreeClassifier(max_features=max_features)\n",
    "num_trees = 100\n",
    "\n",
    "model = BaggingClassifier(base_estimator=rf, n_estimators=num_trees, random_state=2020)\n",
    "results = model_selection.cross_val_score(model, x, y, cv=kfold)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.77 (+/- 0.04)\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\",names=names)\n",
    "\n",
    "array = dataframe.values\n",
    "x = array[:,0:8]\n",
    "y = array[:,8]\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=2020,shuffle=True)\n",
    "rf = DecisionTreeClassifier()\n",
    "num_trees = 100\n",
    "max_features = 3\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=2020,shuffle=True)\n",
    "model = RandomForestClassifier(n_estimators=num_trees, max_features=max_features)\n",
    "results = model_selection.cross_val_score(model, x, y, cv=kfold)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaboost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Boosting : F1 Score 0.95, Accuracy 0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "breast_cancer = load_breast_cancer()\n",
    "x = pd.DataFrame(breast_cancer.data, columns=breast_cancer.feature_names)\n",
    "y = pd.Categorical.from_codes(breast_cancer.target, breast_cancer.target_names)\n",
    "# Transforming string Target to an int\n",
    "encoder = LabelEncoder()\n",
    "binary_encoded_y = pd.Series(encoder.fit_transform(y))\n",
    "\n",
    "#Train Test Split\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, binary_encoded_y, random_state=1)\n",
    "clf_boosting = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=200\n",
    ")\n",
    "clf_boosting.fit(train_x, train_y)\n",
    "predictions = clf_boosting.predict(test_x)\n",
    "print(\"For Boosting : F1 Score {}, Accuracy {}\".format(round(f1_score(test_y,predictions),2),round(accuracy_score(test_y,predictions),2)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest as a bagging classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Bagging : F1 Score 0.88, Accuracy 0.91\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "breast_cancer = load_breast_cancer()\n",
    "x = pd.DataFrame(breast_cancer.data, columns=breast_cancer.feature_names)\n",
    "y = pd.Categorical.from_codes(breast_cancer.target, breast_cancer.target_names)\n",
    "# Transforming string Target to an int\n",
    "encoder = LabelEncoder()\n",
    "binary_encoded_y = pd.Series(encoder.fit_transform(y))\n",
    "\n",
    "#Train Test Split\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, binary_encoded_y, random_state=1)\n",
    "clf_bagging = RandomForestClassifier(n_estimators=200, max_depth=1)\n",
    "clf_bagging.fit(train_x, train_y)\n",
    "predictions = clf_bagging.predict(test_x)\n",
    "print(\"For Bagging : F1 Score {}, Accuracy {}\".format(round(f1_score(test_y,predictions),2),round(accuracy_score(test_y,predictions),2)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are trying an example of Stacking and compare it to a Bagging & a Boosting. \n",
    "\n",
    "We note that, many other applications (datasets) would show more difference between these techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Bagging : F1 Score 0.88, Accuracy 0.9\n",
      "For Boosting : F1 Score 0.93, Accuracy 0.94\n",
      "For Stacking : F1 Score 0.98, Accuracy 0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "breast_cancer = load_breast_cancer()\n",
    "x = pd.DataFrame(breast_cancer.data, columns=breast_cancer.feature_names)\n",
    "y = pd.Categorical.from_codes(breast_cancer.target, breast_cancer.target_names)\n",
    "\n",
    "# Transforming string Target to an int\n",
    "encoder = LabelEncoder()\n",
    "binary_encoded_y = pd.Series(encoder.fit_transform(y))\n",
    "\n",
    "#Train Test Split\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, binary_encoded_y, random_state=2020)\n",
    "\n",
    "boosting_clf_ada_boost= AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=3\n",
    ")\n",
    "bagging_clf_rf = RandomForestClassifier(n_estimators=200, max_depth=1,random_state=2020)\n",
    "\n",
    "\n",
    "clf_rf = RandomForestClassifier(n_estimators=200, max_depth=1,random_state=2020)\n",
    "clf_ada_boost = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1,random_state=2020),\n",
    "    n_estimators=3\n",
    ")\n",
    "\n",
    "clf_logistic_reg = LogisticRegression(solver='liblinear',random_state=2020)\n",
    "\n",
    "#Customizing and Exception message\n",
    "class NumberOfClassifierException(Exception):\n",
    "    pass\n",
    "\n",
    "#Creating a stacking class\n",
    "class Stacking():\n",
    "\n",
    "    '''\n",
    "        This is a test class for stacking !\n",
    "        Please fill Free to change it to fit your needs\n",
    "        We suppose that at least the First N-1 Classifiers have\n",
    "        a predict_proba function.\n",
    "    '''\n",
    "\n",
    "    def __init__(self,classifiers):\n",
    "        if(len(classifiers) < 2):\n",
    "            raise numberOfClassifierException(\"You must fit your classifier with 2 classifiers at least\");\n",
    "        else:\n",
    "            self._classifiers = classifiers\n",
    "\n",
    "\n",
    "    def fit(self,data_x,data_y):\n",
    "\n",
    "        stacked_data_x = data_x.copy()\n",
    "        for classfier in self._classifiers[:-1]:\n",
    "            classfier.fit(data_x,data_y)\n",
    "            stacked_data_x = np.column_stack((stacked_data_x,classfier.predict_proba(data_x)))\n",
    "\n",
    "\n",
    "        last_classifier = self._classifiers[-1]\n",
    "        last_classifier.fit(stacked_data_x,data_y)\n",
    "\n",
    "\n",
    "    def predict(self,data_x):\n",
    "\n",
    "        stacked_data_x = data_x.copy()\n",
    "        for classfier in self._classifiers[:-1]:\n",
    "            prob_predictions = classfier.predict_proba(data_x)\n",
    "            stacked_data_x = np.column_stack((stacked_data_x,prob_predictions))\n",
    "\n",
    "        last_classifier = self._classifiers[-1]\n",
    "        return last_classifier.predict(stacked_data_x)\n",
    "\n",
    "\n",
    "\n",
    "bagging_clf_rf.fit(train_x, train_y)\n",
    "boosting_clf_ada_boost.fit(train_x, train_y)\n",
    "\n",
    "classifers_list = [clf_rf,clf_ada_boost,clf_logistic_reg]\n",
    "clf_stacking = Stacking(classifers_list)\n",
    "clf_stacking.fit(train_x,train_y)\n",
    "\n",
    "predictions_bagging = bagging_clf_rf.predict(test_x)\n",
    "predictions_boosting = boosting_clf_ada_boost.predict(test_x)\n",
    "predictions_stacking = clf_stacking.predict(test_x)\n",
    "\n",
    "print(\"For Bagging : F1 Score {}, Accuracy {}\".format(round(f1_score(test_y,predictions_bagging),2),round(accuracy_score(test_y,predictions_bagging),2)))\n",
    "print(\"For Boosting : F1 Score {}, Accuracy {}\".format(round(f1_score(test_y,predictions_boosting),2),round(accuracy_score(test_y,predictions_boosting),2)))\n",
    "print(\"For Stacking : F1 Score {}, Accuracy {}\".format(round(f1_score(test_y,predictions_stacking),2),round(accuracy_score(test_y,predictions_stacking),2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enviro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9447cf5e61ce3dc51211b6598d1b971090e7a72d147764f76841fc6e39a335b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
